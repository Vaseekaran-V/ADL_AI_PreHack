{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funny-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "#Import other necessary model libraries, for this example, using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painted-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['next_month_plan'] = train_data['next_month_plan'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cardiovascular-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PKG2', 'PKG1', 'PKG6', 'PKG4', 'PKG5', 'PKG3', 'PKG8', 'PKG7']\n",
       "Categories (8, object): ['PKG2', 'PKG1', 'PKG6', 'PKG4', 'PKG5', 'PKG3', 'PKG8', 'PKG7']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['next_month_plan'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "light-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_x = ['PKG0','PKG1', 'PKG2', 'PKG3', 'PKG4', 'PKG5', 'PKG6', 'PKG7', 'PKG8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "classical-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-antibody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(labels_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fuzzy-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['encoded_class_labels'] = le.transform(train_data['next_month_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "linear-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Smartphone', 'Basic', 'Feature phone', 'Pluggable card', 'Tablet',\n",
       "       nan, 'Modem'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['device_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "combined-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['device_type'] = train_data['device_type'].fillna(value = 'Unknown')\n",
    "train_data['device_category'] = train_data['device_category'].fillna(value = 'Unknown')\n",
    "train_data['gender'] = train_data['gender'].fillna(value = 'Unknown')\n",
    "train_data['age_group'] = train_data['age_group'].fillna(value = 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "purple-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns = ['next_month_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polished-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['dusage_avg'] = train_data['dusage_avg'].fillna(value = 0)\n",
    "train_data['vusage_offnet_avg'] = train_data['vusage_offnet_avg'].fillna(value = 0)\n",
    "train_data['add_on_tot_rental'] = train_data['add_on_tot_rental'].fillna(value = -1)\n",
    "train_data['add_on_count'] = train_data['add_on_count'].fillna(value = 0)\n",
    "train_data['vusage_onnet_avg'] = train_data['vusage_onnet_avg'].fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offensive-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10500 entries, 0 to 10499\n",
      "Data columns (total 31 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   primary_identifier           10500 non-null  int64  \n",
      " 1   device_type                  10500 non-null  object \n",
      " 2   device_category              10500 non-null  object \n",
      " 3   gender                       10500 non-null  object \n",
      " 4   district_name                10500 non-null  object \n",
      " 5   age_group                    10500 non-null  object \n",
      " 6   network_stay                 10500 non-null  int64  \n",
      " 7   average_monthly_bill_amount  10500 non-null  float64\n",
      " 8   dusage_sum                   10500 non-null  float64\n",
      " 9   dusage_min                   10500 non-null  float64\n",
      " 10  dusage_max                   10500 non-null  float64\n",
      " 11  dusage_avg                   10500 non-null  float64\n",
      " 12  dusage_days                  10500 non-null  float64\n",
      " 13  dusage_stddev                10500 non-null  float64\n",
      " 14  vusage_onnet_sum             10500 non-null  float64\n",
      " 15  vusage_onnet_max             10500 non-null  float64\n",
      " 16  vusage_onnet_min             10500 non-null  float64\n",
      " 17  vusage_onnet_days            10500 non-null  float64\n",
      " 18  vusage_onnet_avg             10500 non-null  float64\n",
      " 19  vusage_onnet_stddev          10500 non-null  float64\n",
      " 20  vusage_offnet_sum            10500 non-null  float64\n",
      " 21  vusage_offnet_max            10500 non-null  float64\n",
      " 22  vusage_offnet_min            10500 non-null  float64\n",
      " 23  vusage_offnet_days           10500 non-null  float64\n",
      " 24  vusage_offnet_avg            10500 non-null  float64\n",
      " 25  vusage_offnet_stddev         10500 non-null  float64\n",
      " 26  number_of_fixed_bb_accounts  10500 non-null  float64\n",
      " 27  number_of_iptv_accounts      10500 non-null  float64\n",
      " 28  add_on_tot_rental            10500 non-null  float64\n",
      " 29  add_on_count                 10500 non-null  float64\n",
      " 30  encoded_class_labels         10500 non-null  int64  \n",
      "dtypes: float64(23), int64(3), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-stick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "organizational-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_types(dataframe):\n",
    "    data_cat_cols = []\n",
    "    data_quan_cols = []\n",
    "    \n",
    "    for col in np.array(dataframe.columns):\n",
    "        if dataframe[col].dtype == 'int64' or dataframe[col].dtype == 'float64':\n",
    "            data_quan_cols.append(col)\n",
    "        elif dataframe[col].dtype == 'O':\n",
    "            data_cat_cols.append(col)\n",
    "            \n",
    "    return data_cat_cols, data_quan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "romantic-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['encoded_class_labels', 'primary_identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binary-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat_cols, data_quan_cols = get_col_types(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arranged-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['encoded_class_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heated-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=10, test_size = 0.05, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "valued-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "quan_pipeline = Pipeline([\n",
    "    ('std_scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "quan_transformed = quan_pipeline.fit_transform(X_train[data_quan_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pursuant-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline = ColumnTransformer([\n",
    "    ('numerical', quan_pipeline, data_quan_cols),\n",
    "    ('categorical', OrdinalEncoder(), data_cat_cols),\n",
    "    \n",
    "])\n",
    "\n",
    "train_data_processed = data_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "suburban-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_processed = data_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-clearance",
   "metadata": {},
   "source": [
    "## Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "metropolitan-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(\"../data/test_dataset_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "super-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data['device_type'] = submission_data['device_type'].fillna(value = 'Unknown')\n",
    "submission_data['device_category'] = submission_data['device_category'].fillna(value = 'Unknown')\n",
    "submission_data['gender'] = submission_data['gender'].fillna(value = 'Unknown')\n",
    "submission_data['age_group'] = submission_data['age_group'].fillna(value = 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "suffering-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data['dusage_avg'] = submission_data['dusage_avg'].fillna(value = 0)\n",
    "submission_data['vusage_offnet_avg'] = submission_data['vusage_offnet_avg'].fillna(value = 0)\n",
    "submission_data['add_on_tot_rental'] = submission_data['add_on_tot_rental'].fillna(value = -1)\n",
    "submission_data['add_on_count'] = submission_data['add_on_count'].fillna(value = 0)\n",
    "submission_data['vusage_onnet_avg'] = submission_data['vusage_onnet_avg'].fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "patient-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_id = submission_data['primary_identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "english-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_X = submission_data.drop(columns=['primary_identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "collective-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_processed = data_pipeline.transform(submission_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-arnold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-healthcare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "robust-anchor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(label_encoder = False, n_estimators = 900, max_depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cubic-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datastorm2/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:53:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              label_encoder=False, learning_rate=0.300000012, max_delta_step=0,\n",
       "              max_depth=20, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=900, n_jobs=16,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_processed, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-springer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "disturbed-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daily-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.82      0.76       183\n",
      "           2       0.38      0.21      0.27        68\n",
      "           3       0.47      0.53      0.50        86\n",
      "           4       0.27      0.22      0.24        37\n",
      "           5       0.64      0.68      0.66        78\n",
      "           6       0.34      0.32      0.33        37\n",
      "           7       0.14      0.11      0.12        18\n",
      "           8       0.44      0.44      0.44        18\n",
      "\n",
      "    accuracy                           0.56       525\n",
      "   macro avg       0.42      0.42      0.42       525\n",
      "weighted avg       0.53      0.56      0.54       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-magazine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "optional-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state = 0,class_weight='balanced', max_depth = 11, max_features = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "amino-things",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=11, max_features=29,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(train_data_processed, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "traditional-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = model_rf.predict(test_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "metropolitan-junior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.72      0.83       211\n",
      "           2       0.43      0.59      0.50        37\n",
      "           3       0.62      0.68      0.65        97\n",
      "           4       0.34      0.63      0.44        30\n",
      "           5       0.74      0.73      0.74        83\n",
      "           6       0.51      0.51      0.51        35\n",
      "           7       0.44      0.29      0.35        14\n",
      "           8       0.52      0.89      0.65        18\n",
      "\n",
      "    accuracy                           0.68       525\n",
      "   macro avg       0.57      0.63      0.58       525\n",
      "weighted avg       0.74      0.68      0.70       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "original-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submission = model_rf.predict(submission_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aggregate-haven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1305, 2: 544, 3: 769, 4: 520, 5: 715, 6: 316, 7: 123, 8: 208}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_submission, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "above-render",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
